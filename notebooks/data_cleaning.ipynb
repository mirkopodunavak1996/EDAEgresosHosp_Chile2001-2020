{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e8c0f7-f22c-4fc7-a65e-ddf111e37c01",
   "metadata": {},
   "source": [
    "## Data preparation and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed96d2-5b96-4be9-aa08-6eb055467608",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82190b01-d31e-44dc-9847-45642f5a29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4a9cf-9d91-48c1-8c03-61e3f34e663e",
   "metadata": {},
   "source": [
    "Defining a global function with local functions created to clean each dataframe. This is useful to save time and standarize the cleaining process over all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04535503-9f66-427d-969b-160ae7d50aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(y):\n",
    "\n",
    "    \"\"\"\n",
    "    Function created to clean dataframes (20) individually before concatenating themFuncion para limpiar dataframe individual antes de concatenarlos todos\n",
    "    Inside the function there are local ones created to perform the specific data cleaning actions\n",
    "    \"\"\"\n",
    "\n",
    "    año_df = f\"Egresos_Hospitalarios_{y}.csv\"\n",
    "    df_limpio = pd.read_csv(año_df, encoding='ISO-8859-1', on_bad_lines='skip', sep = \";\", low_memory=False)\n",
    "    \n",
    "\n",
    "    def importacion(df):\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df = df[[\"SEXO\",\"EDAD_A_OS\",\"PREVISION\", \"PERTENENCIA_ESTABLECIMIENTO_SALUD\", \"GLOSA_ESTABLECIMIENTO_SALUD\",\n",
    "             \"DIAS_ESTADA\",\"CONDICION_EGRESO\",\"DIAG1\",\"GLOSA_DIAG1\"]].copy()\n",
    "        df.dropna(inplace = True)\n",
    "        df[\"Año\"] = f\"{y}\"\n",
    "        df[\"Año\"] = pd.to_datetime(df[\"Año\"]).dt.year\n",
    "        df[\"SEXO\"] = df[\"SEXO\"].astype(str)\n",
    "        df[\"PREVISION\"] = df[\"PREVISION\"].astype(str)\n",
    "        df[\"CONDICION_EGRESO\"] = df[\"CONDICION_EGRESO\"].astype(str)\n",
    "        return df\n",
    "\n",
    "    def tipo_col(df):\n",
    "        df[\"SEXO\"] = df[\"SEXO\"].astype(str)\n",
    "        df[\"PREVISION\"] = df[\"PREVISION\"].astype(str)\n",
    "        df[\"CONDICION_EGRESO\"] = df[\"CONDICION_EGRESO\"].astype(str)\n",
    "        return df\n",
    "\n",
    "    def sexo(x):\n",
    "        if x == \"2\" or x == \"2\":\n",
    "            x = \"Mujer\"\n",
    "        elif x == \"1\" or x == \"1.0\":\n",
    "            x = \"Hombre\"\n",
    "        else:\n",
    "            x = \"Otro\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def prevision(x):\n",
    "        if x == \"1\" or x == \"1.0\":\n",
    "            x = \"Fonasa\"\n",
    "        elif x == \"2\" or x == \"2.0\":\n",
    "            x = \"Isapre\"\n",
    "        else:\n",
    "            x = \"Eliminar\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def condicion(x):\n",
    "        if x == \"1.0\" or x == \"1\":\n",
    "            x = \"Vivo\"\n",
    "        elif x == \"2.0\" or x == \"2\":\n",
    "            x = \"Muerto\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def pubpriv(x):\n",
    "       if x == \"Pertenecientes al Sistema Nacional de Servicios de Salud, SNSS\":\n",
    "           x = \"Publico\"\n",
    "       elif x == \"No Pertenecientes al Sistema Nacional de Servicios de Salud, SNSS\":\n",
    "            x = \"Privado\"\n",
    "        \n",
    "       return x\n",
    "\n",
    "    def col_transformation(data):\n",
    "        data[\"SEXO\"] = data[\"SEXO\"].apply(sexo)\n",
    "        data[\"PREVISION\"] = data[\"PREVISION\"].apply(prevision)\n",
    "        data[\"CONDICION_EGRESO\"] = data[\"CONDICION_EGRESO\"].apply(condicion)\n",
    "        data[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"] = data[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"].apply(pubpriv)\n",
    "        data = data[data['PREVISION'] != 'Eliminar']\n",
    "        data = data[data['SEXO'] != 'Otro']\n",
    "\n",
    "        return data\n",
    "\n",
    "    df_limpio = importacion(df_limpio)\n",
    "    df_limpio = tipo_col(df_limpio)\n",
    "    df_limpio = col_transformation(df_limpio)\n",
    "\n",
    "    return df_limpio\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf5200-18b8-4c8e-8984-9690c9fe4275",
   "metadata": {},
   "source": [
    "Looping over the 20 dataframes to import, clean and store them dinamically. Again, this is more efficient than just applying the function over each dataframe separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab7cbb9-b669-42e3-ba0b-72fe4b7877e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file paths. This formatting works to import the raw data only if the files are stored in the same folder as the notebook you are using\n",
    "archivos = [f\"Egresos_Hospitalarios_{año}.csv\" for año in range(2001, 2021)]\n",
    "\n",
    "# Initialize an empty dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through the file paths and load each file into the dictionary\n",
    "for i, file in enumerate(archivos):\n",
    "    # Dynamically create a name for each DataFrame, e.g., \"df_1\", \"df_2\", etc.\n",
    "    dataframe_name = f\"df_{i+2001}\"\n",
    "    \n",
    "    # Load the CSV into a DataFrame and store it in the dictionary\n",
    "    dataframes[dataframe_name] = limpieza(f\"{i+2001}\")\n",
    "\n",
    "# Access DataFrames by their names\n",
    "# print(dataframes[\"df_2005\"].head())  # View the first few rows of the first DataFrame\n",
    "# print(dataframes[\"df_2007\"].info())  # View information about the second DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb59659-7aa9-4349-8196-3925177c9e19",
   "metadata": {},
   "source": [
    "With the raw dataframes imported and cleaned it is the moment to concatenate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb71b3a5-09ab-40e4-a363-3e6980ac83b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26337902, 10)\n"
     ]
    }
   ],
   "source": [
    "# Concatenar:\n",
    "combined_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "print(combined_df.shape)\n",
    "\n",
    "# sin eliminar nulos: (26340664, 10)\n",
    "# eliminando nulos: (26337902, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4792c51-dbf3-4388-941d-b7c1d65100ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"Egresos_2001-2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263d07e-f11a-4796-a4bb-3de3ecbaacf5",
   "metadata": {},
   "source": [
    "Over the concatenated dataframe, the data types of some columns are changed to enhance future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09be1f7-8209-4085-aec1-ccd4ad6bebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"SEXO\"] = combined_df[\"SEXO\"].astype(\"category\")\n",
    "combined_df[\"PREVISION\"] = combined_df[\"PREVISION\"].astype(\"category\")\n",
    "combined_df[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"] = combined_df[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"].astype(\"category\")\n",
    "combined_df[\"DIAS_ESTADA\"] = combined_df[\"DIAS_ESTADA\"].astype(np.int32)\n",
    "combined_df[\"CONDICION_EGRESO\"] = combined_df[\"CONDICION_EGRESO\"].astype(\"category\")\n",
    "combined_df[\"EDAD_A_OS\"] = combined_df[\"EDAD_A_OS\"].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d1cb6f8-e3e3-4eac-8e8e-584b23c32dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26337902 entries, 0 to 26337901\n",
      "Data columns (total 10 columns):\n",
      " #   Column                             Dtype   \n",
      "---  ------                             -----   \n",
      " 0   SEXO                               category\n",
      " 1   EDAD_A_OS                          int32   \n",
      " 2   PREVISION                          category\n",
      " 3   PERTENENCIA_ESTABLECIMIENTO_SALUD  category\n",
      " 4   GLOSA_ESTABLECIMIENTO_SALUD        object  \n",
      " 5   DIAS_ESTADA                        int32   \n",
      " 6   CONDICION_EGRESO                   category\n",
      " 7   DIAG1                              object  \n",
      " 8   GLOSA_DIAG1                        object  \n",
      " 9   Año                                int32   \n",
      "dtypes: category(4), int32(3), object(3)\n",
      "memory usage: 1004.7+ MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392290c-5646-4bb5-aa85-5715c07c07f9",
   "metadata": {},
   "source": [
    "The dataframe is transformed into a parquet file, which is lighter and easier to import into other notebooks or upload to Kaggle to share it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bfe8185-fc09-4e4b-bbcc-cb370a51afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_parquet('Egresos_2001-2020.parquet', index=False)  # Save as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0303ce-651d-474a-ac8c-6f54579de2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
